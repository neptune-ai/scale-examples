{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune + PyTorch\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/scale-examples/blob/lr%2Fpytorch_example/integrations-and-supported-tools/pytorch/notebooks/pytorch_text_model_debugging.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/> \n",
    "</a>\n",
    "\n",
    "## Logging and visualizing debugging metrics with Neptune\n",
    "Global metrics (e.g., loss, accuracy) provide a high-level performance snapshot and ensure training is on course. However, for large or foundation models, monitoring layer-wise metrics—such as gradients and activations—delivers critical insights into how each layer learns. This level of detail helps identify issues (e.g., vanishing/exploding gradients) and fine-tune individual layers for better overall performance.\n",
    "The **main challenge** is the sheer volume of data generated by layer-wise logging. Fortunately, Neptune is built for hyperscale tracking, enabling you to efficiently capture, organize, and analyze metrics from every layer—no matter how large your model—without disrupting the training process.\n",
    "\n",
    "### Introduction\n",
    "This example is designed to be used as a code recipe for you to re-use sections with your own code to edit or adapt to your own model training needs. \n",
    "\n",
    "This guide will show you how to:\n",
    "- Initialize the **Neptune Run** object and log configuration parameters\n",
    "- Create a **reuseable class** to hook layer-wise metrics (`HookManager`)\n",
    "- Log **aggregated metrics** such as loss and accuracy\n",
    "- Log **layer-wise metrics** to debug model traing such as;\n",
    "\n",
    "| **Metric**                        | **Demonstrated** | **What it Shows**                                                                                             | **How to Capture**                                             |\n",
    "|-----------------------------------|--------------------------------------|--------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------|\n",
    "| **Activations**                   | Yes                                  | Dead or exploding activations can indicate issues with training stability. | `HookManager`            |\n",
    "| **Gradients**                     | Yes                                  | Essential for diagnosing vanishing or exploding gradients. Small gradients may indicate vanishing gradients, while large ones can signal instability. | `HookManager`        |\n",
    "| **Parameters**            | Yes                                  | Tracks how the model’s parameters evolve during training. Large or small weights may indicate the need for better regularization or adjustments in learning rate. | Extract directly from the model’s parameters.                  |\n",
    "| **Loss**               | No                                   | Identifies which parts of the network contribute more to the overall loss, aiding debugging and optimization. | Monitor outputs from each layer and compare with the target.   |\n",
    "| **Learning Rate**       | No                                   | Helpful if using techniques like Layer-wise Learning Rate Decay (L2LRD). Tracking this can provide insight into the layer-specific learning rate. | Manually track based on optimizer settings.                    |\n",
    "| **Output Norms**            | No                                   | The L2-norm of layer outputs can highlight issues like gradient explosion or vanishing gradients. | Compute the L2-norm for each layer’s output.                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "  1. Create a Neptune Scale account. [Register &rarr;](https://neptune.ai/early-access)\n",
    "  2. Create a Neptune project that you will use for tracking metadata. For instructions, see [Projects](https://docs-beta.neptune.ai/projects/) in the Neptune Scale docs.\n",
    "  3. Install and configure Neptune Scale for logging metadata. For instructions, see [Get started](https://docs-beta.neptune.ai/setup) in the Neptune Scale docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment variables\n",
    "Once you have your project and workspace names as well as your API token from the UI, you can set them as environment variables to be used through this notebook. Uncomment the code block below and replace with your own details.\n",
    "```python \n",
    "# Set Neptune credentials as environment variables\n",
    "%env NEPTUNE_API_TOKEN = \"your_api_token_here\"\n",
    "%env NEPTUNE_PROJECT = \"your_workspace_name_here/your_project_name_here\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Neptune credentials as environment variables\n",
    "# %env NEPTUNE_API_TOKEN = \"your_api_token_here\"\n",
    "# %env NEPTUNE_PROJECT = \"your_workspace_name_here/your_project_name_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "! pip install -q -U neptune_scale torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "\n",
    "from neptune_scale import Run\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "\n",
    "params = {\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"batch_size\": 8,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 5, \n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"input_features\": 256,\n",
    "    \"embed_size\": 1000,\n",
    "    \"hidden_size\": 256, # hidden size for the LSTM\n",
    "    \"dropout_prob\": 0.3,\n",
    "    \"num_lstm_layers\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download or use next token prediction dataset\n",
    "The dataset used in this example is taken from [HuggingFace](https://huggingface.co/datasets/Na0s/Next_Token_Prediction_dataset). In this example, you can increase the size of the dataset to test the logging capabilities of Neptune, but note that increasing the dataset size will increase the time taken for the full dataset to download. The current setup only downloads the first parquet file from the Hugging Face public dataset. The validation dataset is also reduced to reduce the training loop execution time - you can increase the validation size by changing the `test_size` key-value pair in the `train_test_split()` method from HF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 81926 \n",
      "Validation samples: 935\n"
     ]
    }
   ],
   "source": [
    "# For the example, download a random subset of 10% of the original dataset\n",
    "base_url = \"https://huggingface.co/datasets/Na0s/Next_Token_Prediction_dataset/resolve/main/data/\"\n",
    "data_files = {\"train\": base_url + \"train-00001-of-00067.parquet\", # download only the first 10 files from the HF dataset\n",
    "              \"validation\": base_url + \"validation-00000-of-00001.parquet\"} #doanload the complete validation dataset\n",
    "\n",
    "data_subset = load_dataset(\"parquet\", data_files = data_files, num_proc=4)\n",
    "# validation_subset = load_dataset(\"parquet\", data_files = {\"validation\": base_url + \"validation-00000-of-00001.parquet\"}, num_proc=4, split=[\"validation[:5%]\"])\n",
    "validation_subset = data_subset.get(\"validation\").train_test_split(test_size=0.1)\n",
    "print(f\"Training samples: {data_subset['train'].num_rows} \\nValidation samples: {validation_subset['test'].num_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `DataLoader` objects\n",
    "* To execute the models with PyTorch, we convert the training and validation datasets to tensors and then setup DataLoader for easier batching in our training loop.\n",
    "* The model architecture requires the vocabulary size as an input and this we calculate the max token from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 128257\n"
     ]
    }
   ],
   "source": [
    "train_subset = data_subset[\"train\"].with_format(type=\"torch\", columns=[\"text\", \"input_ids\", \"labels\"]) # HF provides methods to convert datatypes to tensors\n",
    "validation_subset = validation_subset[\"test\"].with_format(type=\"torch\", columns=[\"text\", \"input_ids\", \"labels\"]) # HF provides methods to convert datatypes to tensors\n",
    "\n",
    "train_dataloader = DataLoader(train_subset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "val_dataloader = DataLoader(validation_subset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "# Determine the vocab size of the dataset\n",
    "# Flatten the list of tokenized sentences into one long list of token IDs\n",
    "vocab_size = max([token for sentence in data_subset[\"train\"][\"input_ids\"] for token in sentence]) + 1\n",
    "params[\"vocab_size\"] = vocab_size\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PyTorch model architecture and helpers\n",
    "We define a simple LLM model architecture using PyTorch. Since this is a text-based example, we use an embedding layer, a LSTM layer and a fully connected layer. This architecture can be adjusted to your needs and increased in size when testing the workflow. To increase the size of the LSTM layers, change the `num_layers` parameter in the parameters dictionary or to increase the number of fully connected layers, update the mode architecture itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the simple LLM model with LSTM\n",
    "class SimpleLLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(SimpleLLM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers = num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)  # LSTM returns output and hidden/cell state tuple\n",
    "        out = self.fc1(lstm_out) # Use the last output from the LSTM\n",
    "        return out\n",
    "\n",
    "# Function to evaluate the model after each epoch/step\n",
    "def evaluate(model, val_dataloader, criterion, device, vocab_size):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass for validation\n",
    "            logits = model(input_ids)  # Shape: (batch_size, seq_len, vocab_size)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = criterion(logits.view(-1, vocab_size), labels.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_loss / len(val_dataloader)\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tracking class\n",
    "\n",
    "This section creates a `HookManager` class that allows us to capture the **activations** and **gradients** from each layer. This class accepts a PyTorch model object as an input. This class will automatically capture the gradients and activations in each layer of the model. Below, you can see a pseudo implementation:\n",
    "\n",
    "```python\n",
    "# Initialize model\n",
    "model = your_ModelClass()\n",
    "# Register hooks\n",
    "hm = HookManager(model)\n",
    "hm.register_hooks()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):\n",
    "    \n",
    "    # Forward pass, e.g. model.train()\n",
    "    # Backward pass, e.g. loss.backward()\n",
    "    \n",
    "    activations = hm.get_activations()\n",
    "    gradients = hm.get_gradients()\n",
    "\n",
    "    # Log values (mean, std, etc.) to Neptune\n",
    "```\n",
    "\n",
    "_Important_: The `HookManager` class can be used in your own training script as it only accepts a model object as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to manage hooks for activations and gradients\n",
    "class HookManager:\n",
    "    def __init__(self, model):\n",
    "        if not isinstance(model, nn.Module):\n",
    "            raise TypeError(\"The model must be a PyTorch model\")\n",
    "        \n",
    "        self.model = model\n",
    "        self.hooks = []\n",
    "        self.activations = {}\n",
    "        self.gradients = {}\n",
    "\n",
    "    # Function to save activations\n",
    "    def save_activation(self, name):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[name] = output\n",
    "        return hook\n",
    "\n",
    "    # Function to save gradients (registering hooks for the model parameters)\n",
    "    def save_gradient(self, name):\n",
    "        def hook(module, grad_input, grad_output):\n",
    "            self.gradients[name] = grad_output[0]\n",
    "        return hook\n",
    "\n",
    "    # Function to register hooks for activations and gradients\n",
    "    def register_hooks(self):\n",
    "        # Register forward hooks for activations\n",
    "        for name, module in self.model.named_modules():\n",
    "            self.hooks.append(module.register_forward_hook(self.save_activation(name)))\n",
    "\n",
    "        # Register backward hooks for gradients\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, (nn.LSTM, nn.Linear)): # You can add more layer types here\n",
    "                self.hooks.append(module.register_full_backward_hook(self.save_gradient(name)))\n",
    "\n",
    "    # Function to clear activations and gradients after use\n",
    "    def clear(self):\n",
    "        self.activations = {}\n",
    "        self.gradients = {}\n",
    "\n",
    "    # Function to get activations\n",
    "    def get_activations(self):\n",
    "        return self.activations\n",
    "\n",
    "    # Function to get gradients\n",
    "    def get_gradients(self):\n",
    "        return self.gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model training\n",
    "### Initialize Neptune run object and log hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune_scale import Run\n",
    "from uuid import uuid4\n",
    "\n",
    "custom_run_id = f\"pytorch-text-{uuid4()}\" # Create your own custom run_id\n",
    "experiment_name = \"pytorch-text\" # Create a run that is the head of an experiment. This will also be used for forking.\n",
    "\n",
    "run = Run(\n",
    "    run_id=custom_run_id,\n",
    "    experiment_name = experiment_name,\n",
    "    )\n",
    "\n",
    "run.log_configs(\n",
    "    {\n",
    "        \"config/learning_rate\": params[\"learning_rate\"],\n",
    "        \"config/optimizer\": params[\"optimizer\"],\n",
    "        \"config/batch_size\": params[\"batch_size\"],\n",
    "        \"config/epochs\": params[\"epochs\"],\n",
    "        \"config/num_lstm_layers\" : params[\"num_lstm_layers\"],\n",
    "        \"data/vocab_size\": params[\"vocab_size\"],\n",
    "        \"data/embed_size\": params[\"embed_size\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "run.add_tags(tags=[params[\"optimizer\"]], group_tags=True)\n",
    "run.add_tags(tags=[\"text\", \"LLM\", \"Simple\"])\n",
    "\n",
    "print(f\"View current experiment: https://scale.neptune.ai/{os.getenv(\"NEPTUNE_PROJECT\")}/runs/details?viewId=standard-view&runIdentificationKey={experiment_name}&type=experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute model training loop\n",
    "In this loop, we configure the `HookManager` and register the hooks. In your training loop, you will need to use the `get_` methods to retrieve the stored values for the activations and gradients after the forward and backward passes are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create links to access active training run. Note - this is not required for the example to run, but for ease of illustration of the tutorial.\n",
    "print(f\"View training charts: https://scale.neptune.ai/{os.getenv(\"NEPTUNE_PROJECT\")}/-/run/?customId={custom_run_id}&detailsTab=charts\")\n",
    "\n",
    "# Training setup\n",
    "debug_metrics = {}\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = SimpleLLM(params[\"vocab_size\"], params[\"embed_size\"], params[\"hidden_size\"], params[\"num_lstm_layers\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr = params[\"learning_rate\"])\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100) # Ignore the buffering index of -100 in the dataset\n",
    "\n",
    "hook_manager = HookManager(model)\n",
    "hook_manager.register_hooks()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "step_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(params[\"epochs\"]):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        model.train()\n",
    "        step_counter += 1\n",
    "        hook_manager.clear()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(input_ids)\n",
    "        \n",
    "        # Compute the loss (ignore padding tokens by masking labels)\n",
    "        loss = criterion(logits.view(-1, vocab_size), labels.view(-1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        print(f\"Step {step_counter} / {len(train_dataloader)}, Loss: {loss.item()}\")\n",
    "\n",
    "        # Track activations\n",
    "        activations = hook_manager.get_activations()\n",
    "        for layer, activation in activations.items():\n",
    "            if layer is not None:\n",
    "                debug_metrics[f\"debug/activation/{layer}_mean\"] = activation[0].mean().item()\n",
    "                debug_metrics[f\"debug/activation/{layer}_std\"] = activation[0].std().item()\n",
    "\n",
    "        # Track gradients with hooks\n",
    "        gradients = hook_manager.get_gradients()\n",
    "        for layer, gradient in gradients.items():\n",
    "            debug_metrics[f\"debug/gradient/{layer}_mean\"] = gradient.mean().item()\n",
    "\n",
    "        # Track gradients per layer at each epoch\n",
    "        for layer, param in model.named_parameters():\n",
    "            if param is not None:\n",
    "                debug_metrics[f\"debug/parameters/{layer}_std\"] = param.grad.std().item()\n",
    "                debug_metrics[f\"debug/parameters/{layer}_mean\"] = param.grad.mean().item()\n",
    "                debug_metrics[f\"debug/parameters/{layer}_norm\"] = param.grad.norm().item() # L2 norm (Euclidean norm) of the gradients\n",
    "\n",
    "        if step_counter % 50 == 0: # Log validation loss at every 50 steps\n",
    "            val_loss = evaluate(model, val_dataloader, criterion, device, vocab_size)\n",
    "\n",
    "            run.log_metrics(\n",
    "                data = {\n",
    "                    \"metrics/train/loss\": loss.item(),\n",
    "                    \"metrics/validation/loss\": val_loss,\n",
    "                    \"epoch/value\": epoch,\n",
    "                    **debug_metrics\n",
    "                },\n",
    "                step = step_counter\n",
    "            )\n",
    "        else: # Log training loss and debugging metrics for each step\n",
    "            run.log_metrics(\n",
    "                data = {\n",
    "                    \"metrics/train/loss\": loss.item(),\n",
    "                    \"epoch/value\": epoch,\n",
    "                    **debug_metrics\n",
    "                },\n",
    "                step = step_counter\n",
    "            )\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_dataloader)}\")\n",
    "\n",
    "# Close run to ensure all operations are processed\n",
    "run.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "While the model is training, you can start using our _super-snappy_ web UI to browse your metrics and create custom analyses and visualizations.\n",
    "\n",
    "### What to do\n",
    "1. Navigate to the charts tab of the active run to visualize the large number of metrics being logged in near real time.\n",
    "2. Filter the metrics using our [advanced regex searching capabilities](https://docs-beta.neptune.ai/charts#filtering-charts). For example, use the following query in the search bar; `.*gradient+.*fc\\d`. This query will filter all metrics for the gradients of the fully connected layers. The more FC layers, the more charts will appear. \n",
    "3. Export this filter to a [dashboard](https://docs-beta.neptune.ai/custom_dashboard), using the _**Duplicate to**_ button. The saved dashboard will now only display these metrics during training.\n",
    "4. Using our [dynamic metric selection](https://docs-beta.neptune.ai/chart_widget#dynamic-metric-selection) feature, you can update the chart widget to display all fully connected layers gradients in one chart. Use the same query as above in the chart widget.\n",
    "5. Create a [custom report](https://docs-beta.neptune.ai/reports) to outline the model training, global metrics, debugging metrics and more.\n",
    "\n",
    "You can see a generic example of the end result [here](https://scale.neptune.ai/o/examples/org/LLM-Pretraining/reports/9e6a2cad-77e7-42df-9d64-28f07d37e908).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neptune_scale_py_312_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
