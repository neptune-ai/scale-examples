{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune + PyTorch\n",
    "\n",
    "Introduction\n",
    "\n",
    "See how Neptune Scale can be used for foundation model traning when you are required to track a large number of metrics across your transformers architecture. \n",
    "\n",
    "This guide will show you how to:\n",
    "- Initialize the Neptune Run object and log configuration parameters\n",
    "- Log standard loss and accuracy metrics to Neptune\n",
    "- Log debugging metrics during model training such as;\n",
    "    * Activations per layer\n",
    "    * Gradients (mean and std weights and biases) per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "  1. Create a Neptune Scale account. [Register &rarr;](https://neptune.ai/early-access)\n",
    "  2. Create a Neptune project that you will use for tracking metadata. For instructions, see [Projects](https://docs-beta.neptune.ai/projects/) in the Neptune Scale docs.\n",
    "  3. Install and configure Neptune Scale for logging metadata. For instructions, see [Get started](https://docs-beta.neptune.ai/setup) in the Neptune Scale docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Neptune and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "! pip install -q -U neptune_scale torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - update config to include model architecture\n",
    "# TODO - Add more hyperparameters\n",
    "# TODO - look at CNN layers\n",
    "# TODO - output and log the model architecture\n",
    "# TODO - check loss and accuracy calculations\n",
    "# TODO - clean up the evaluation function to exclude tracking gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"batch_size\": 256,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 5, \n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"input_features\": 256,\n",
    "    \"n_classes\": 10,\n",
    "    \"input_size\": 28 * 28\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and transform the data for training\n",
    "In this example, we will be using the MINST dataset as part of the PyTorch library for illustration. We create a train, validation and test dataset and apply a transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform to normalize the data and convert it to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizing the image to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)  # Use test set as validation\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader for training, validation, and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=params[\"batch_size\"], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simple Convolutional Neural Network model for MNIST\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Input channels = 1 (grayscale images)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Flattened size of image after convolution layers\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output classes for digits 0-9\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)  # Pooling layer to downsample\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor for the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define layers (increase number of layers)\n",
    "        self.fc1 = nn.Linear(params[\"input_size\"], params[\"input_features\"]) \n",
    "        self.fc2 = nn.Linear(params[\"input_features\"], 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, params[\"n_classes\"])      # Output layer (10 classes for MNIST)\n",
    "\n",
    "        # Registering hooks to track activations\n",
    "        self.hooks = []\n",
    "        self.hooks.append(self.fc1.register_forward_hook(self.save_activation(\"fc1\")))\n",
    "        self.hooks.append(self.fc2.register_forward_hook(self.save_activation(\"fc2\")))\n",
    "        self.hooks.append(self.fc3.register_forward_hook(self.save_activation(\"fc3\")))\n",
    "        self.hooks.append(self.fc1.register_forward_hook(self.save_activation(\"fc4\")))\n",
    "        self.hooks.append(self.fc1.register_forward_hook(self.save_activation(\"fc5\")))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, params[\"input_size\"])  # Flatten the input image (28x28)\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation\n",
    "        x = torch.relu(self.fc2(x))  # Apply ReLU activation\n",
    "        x = torch.relu(self.fc3(x))  # Apply ReLU activation\n",
    "        x = torch.relu(self.fc4(x))  # Apply ReLU activation\n",
    "        x = self.fc5(x)  # Output layer\n",
    "        return x\n",
    "    \n",
    "        # Function to save activations\n",
    "    def save_activation(self, name):\n",
    "        def hook(model, input, output):\n",
    "            self.activations[name] = output\n",
    "        return hook\n",
    "    \n",
    "    def get_activations(self):\n",
    "        return self.activations\n",
    "\n",
    "    def clear_activations(self):\n",
    "        self.activations = {}\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "#model = SimpleCNN()\n",
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "\n",
    "# Select an optimizer\n",
    "if params[\"optimizer\"] == \"Adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
    "    print(params[\"optimizer\"])\n",
    "elif params[\"optimizer\"] == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params[\"learning_rate\"])\n",
    "    print(params[\"optimizer\"])\n",
    "else:\n",
    "    print(\"No optimizer selected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model (validation/test) with gradients tracked\n",
    "def evaluate(model, data_loader, track_gradients=False):\n",
    "    model.train() if track_gradients else model.eval()  # Ensure model is in training mode if tracking gradients\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        for data, target in data_loader:\n",
    "            # Forward pass (with gradient tracking if specified)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)  # Correct loss computation\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if track_gradients:\n",
    "                # Track gradients (we will backpropagate but do not update model parameters)\n",
    "                loss.backward()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_preds += target.size(0)\n",
    "            correct_preds += (predicted == target).sum().item()\n",
    "    \n",
    "    accuracy = correct_preds / total_preds\n",
    "    return epoch_loss / len(data_loader), accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neptune - Initialize Training Run and Log Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neptune parameters\n",
    "from neptune_scale import Run\n",
    "from uuid import uuid4\n",
    "\n",
    "run = Run(\n",
    "    project = \"leo/pytorch-tutorial\",\n",
    "    run_id=f\"pytorch-{uuid4()}\"\n",
    "    )\n",
    "\n",
    "run.log_configs(\n",
    "    {\n",
    "        \"config/learning_rate\": params[\"learning_rate\"],\n",
    "        \"config/optimizer\": params[\"optimizer\"],\n",
    "        \"config/batch_size\": params[\"batch_size\"],\n",
    "        \"config/epochs\": params[\"epochs\"],\n",
    "        \"config/input_size\": params[\"input_size\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "run.add_tags(tags=[params[\"optimizer\"]], group_tags=True)\n",
    "run.add_tags(tags=[\"Torch-MINST\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neptune - Log Metrics while Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Training complete. Loss: 0.8909, Accuracy: 68.81%\n",
      "{'layers/layer_fc1/activation_mean': -28.729677200317383, 'layers/layer_fc4/activation_mean': -28.729677200317383, 'layers/layer_fc5/activation_mean': -28.729677200317383, 'layers/layer_fc2/activation_mean': -2.5397043228149414, 'layers/layer_fc3/activation_mean': -3.0052473545074463, 'layers/layer_fc1/activation_std': 10.17672348022461, 'layers/layer_fc4/activation_std': 10.17672348022461, 'layers/layer_fc5/activation_std': 10.17672348022461, 'layers/layer_fc2/activation_std': 2.3032867908477783, 'layers/layer_fc3/activation_std': 3.2448129653930664, 'layers/layer_fc1.weight_mean': -5.6409244280075654e-05, 'layers/layer_fc1.bias_mean': 8.269915269920602e-05, 'layers/layer_fc2.weight_mean': -2.23042461584555e-05, 'layers/layer_fc2.bias_mean': -4.0248556615551934e-05, 'layers/layer_fc3.weight_mean': -1.6235278962994926e-05, 'layers/layer_fc3.bias_mean': -8.13562364783138e-05, 'layers/layer_fc4.weight_mean': -7.563584222225472e-05, 'layers/layer_fc4.bias_mean': -0.00028862591716460884, 'layers/layer_fc5.weight_mean': 1.3050055480690048e-09, 'layers/layer_fc5.bias_mean': 1.862645149230957e-09, 'layers/layer_fc1.weight_std': 0.0022773402743041515, 'layers/layer_fc1.bias_std': 0.0024427783209830523, 'layers/layer_fc2.weight_std': 0.0020020941738039255, 'layers/layer_fc2.bias_std': 0.0015959893353283405, 'layers/layer_fc3.weight_std': 0.0006584679940715432, 'layers/layer_fc3.bias_std': 0.0010985822882503271, 'layers/layer_fc4.weight_std': 0.0016911266138777137, 'layers/layer_fc4.bias_std': 0.0016698684776201844, 'layers/layer_fc5.weight_std': 0.016184095293283463, 'layers/layer_fc5.bias_std': 0.014144722372293472, 'grad_norm/fc1.weight': 1.020559310913086, 'grad_norm/fc1.bias': 0.03903047367930412, 'grad_norm/fc2.weight': 0.7248778939247131, 'grad_norm/fc2.bias': 0.036089323461055756, 'grad_norm/fc3.weight': 0.2384623885154724, 'grad_norm/fc3.bias': 0.01759118027985096, 'grad_norm/fc4.weight': 0.3064279556274414, 'grad_norm/fc4.bias': 0.019099673256278038, 'grad_norm/fc5.weight': 0.5787935256958008, 'grad_norm/fc5.bias': 0.042434170842170715}\n",
      "Epoch [2/5] Training complete. Loss: 0.2732, Accuracy: 91.75%\n",
      "{'layers/layer_fc1/activation_mean': -28.754409790039062, 'layers/layer_fc4/activation_mean': -28.754409790039062, 'layers/layer_fc5/activation_mean': -28.754409790039062, 'layers/layer_fc2/activation_mean': -3.4414615631103516, 'layers/layer_fc3/activation_mean': -3.730855703353882, 'layers/layer_fc1/activation_std': 10.266525268554688, 'layers/layer_fc4/activation_std': 10.266525268554688, 'layers/layer_fc5/activation_std': 10.266525268554688, 'layers/layer_fc2/activation_std': 2.995718479156494, 'layers/layer_fc3/activation_std': 3.8177525997161865, 'layers/layer_fc1.weight_mean': 7.965337863424793e-05, 'layers/layer_fc1.bias_mean': -9.780008986126631e-05, 'layers/layer_fc2.weight_mean': -1.2387715287331957e-05, 'layers/layer_fc2.bias_mean': 2.7172100089956075e-06, 'layers/layer_fc3.weight_mean': -1.2878872439614497e-05, 'layers/layer_fc3.bias_mean': -8.313333091791719e-05, 'layers/layer_fc4.weight_mean': -2.042674896074459e-05, 'layers/layer_fc4.bias_mean': -0.0001337243738817051, 'layers/layer_fc5.weight_mean': 1.2068994414971002e-10, 'layers/layer_fc5.bias_mean': -3.2596289556430236e-10, 'layers/layer_fc1.weight_std': 0.0020513804629445076, 'layers/layer_fc1.bias_std': 0.0022429414093494415, 'layers/layer_fc2.weight_std': 0.0027040187269449234, 'layers/layer_fc2.bias_std': 0.0019432309782132506, 'layers/layer_fc3.weight_std': 0.0007950548897497356, 'layers/layer_fc3.bias_std': 0.0013046229723840952, 'layers/layer_fc4.weight_std': 0.002085754182189703, 'layers/layer_fc4.bias_std': 0.0016170400194823742, 'layers/layer_fc5.weight_std': 0.022946881130337715, 'layers/layer_fc5.bias_std': 0.01414299663156271, 'grad_norm/fc1.weight': 0.9197079539299011, 'grad_norm/fc1.bias': 0.035851072520017624, 'grad_norm/fc2.weight': 0.9789657592773438, 'grad_norm/fc2.bias': 0.043927378952503204, 'grad_norm/fc3.weight': 0.2878772020339966, 'grad_norm/fc3.bias': 0.02087557688355446, 'grad_norm/fc4.weight': 0.37757423520088196, 'grad_norm/fc4.bias': 0.018285810947418213, 'grad_norm/fc5.weight': 0.8206518888473511, 'grad_norm/fc5.bias': 0.04242899268865585}\n",
      "Epoch [3/5] Training complete. Loss: 0.2083, Accuracy: 93.61%\n",
      "{'layers/layer_fc1/activation_mean': -28.73628807067871, 'layers/layer_fc4/activation_mean': -28.73628807067871, 'layers/layer_fc5/activation_mean': -28.73628807067871, 'layers/layer_fc2/activation_mean': -4.065245151519775, 'layers/layer_fc3/activation_mean': -5.453749656677246, 'layers/layer_fc1/activation_std': 10.463916778564453, 'layers/layer_fc4/activation_std': 10.463916778564453, 'layers/layer_fc5/activation_std': 10.463916778564453, 'layers/layer_fc2/activation_std': 3.5451228618621826, 'layers/layer_fc3/activation_std': 5.318454742431641, 'layers/layer_fc1.weight_mean': 9.08636320673395e-06, 'layers/layer_fc1.bias_mean': -1.3908885193814058e-05, 'layers/layer_fc2.weight_mean': -2.5884002752718516e-05, 'layers/layer_fc2.bias_mean': -8.652423275634646e-05, 'layers/layer_fc3.weight_mean': -1.641714152356144e-05, 'layers/layer_fc3.bias_mean': -8.157885167747736e-05, 'layers/layer_fc4.weight_mean': -3.9947924960870296e-05, 'layers/layer_fc4.bias_mean': -0.00012426286411937326, 'layers/layer_fc5.weight_mean': 3.299284456748097e-10, 'layers/layer_fc5.bias_mean': 1.8626451769865326e-10, 'layers/layer_fc1.weight_std': 0.0009469661745242774, 'layers/layer_fc1.bias_std': 0.0010165267158299685, 'layers/layer_fc2.weight_std': 0.0015304741682484746, 'layers/layer_fc2.bias_std': 0.0007763532339595258, 'layers/layer_fc3.weight_std': 0.000502292939927429, 'layers/layer_fc3.bias_std': 0.0006498315487988293, 'layers/layer_fc4.weight_std': 0.0015387408202514052, 'layers/layer_fc4.bias_std': 0.0010592670878395438, 'layers/layer_fc5.weight_std': 0.016189604997634888, 'layers/layer_fc5.bias_std': 0.010295048356056213, 'grad_norm/fc1.weight': 0.4242599606513977, 'grad_norm/fc1.bias': 0.016234157606959343, 'grad_norm/fc2.weight': 0.5541679263114929, 'grad_norm/fc2.bias': 0.017658572643995285, 'grad_norm/fc3.weight': 0.18194584548473358, 'grad_norm/fc3.bias': 0.010458745993673801, 'grad_norm/fc4.weight': 0.27863141894340515, 'grad_norm/fc4.bias': 0.012019835412502289, 'grad_norm/fc5.weight': 0.5789905786514282, 'grad_norm/fc5.bias': 0.03088514506816864}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 47\u001b[0m\n\u001b[0;32m     43\u001b[0m batch_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m correct_preds \u001b[38;5;241m/\u001b[39m total_preds\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.2f}%\")\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         \n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Validation step per training step\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Evaluate after each step\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# print(f\"Validation at step [{batch_idx+1}/{len(train_loader)}] - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\u001b[39;00m\n\u001b[0;32m     50\u001b[0m run\u001b[38;5;241m.\u001b[39mlog_metrics(\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics/train/loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_counter\n\u001b[0;32m     59\u001b[0m )\n",
      "Cell \u001b[1;32mIn[46], line 8\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, track_gradients)\u001b[0m\n\u001b[0;32m      6\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient tracking during evaluation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Forward pass (with gradient tracking if specified)\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Correct loss computation\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leo.breedt\\miniconda3\\envs\\neptune_scale_py_312_base\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:920\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    917\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    919\u001b[0m dtype \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m--> 920\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "activation_dict_mean = {}\n",
    "activation_dict_std = {}\n",
    "params_dict_std = {}\n",
    "params_dict_mean = {}\n",
    "grad_norms = {}\n",
    "\n",
    "num_epochs = params[\"epochs\"]\n",
    "step_counter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    # Reset activations for each epoch\n",
    "    model.clear_activations()\n",
    "    \n",
    "    # Training step\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        step_counter += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_preds += target.size(0)\n",
    "        correct_preds += (predicted == target).sum().item()\n",
    "        \n",
    "        # Print loss and accuracy for each batch (step)\n",
    "        #if (batch_idx + 1) % 5 == 0:  # Every 5 steps\n",
    "        batch_accuracy = 100 * correct_preds / total_preds\n",
    "        # print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.2f}%\")\n",
    "                \n",
    "        # Validation step per training step\n",
    "        val_loss, val_accuracy = evaluate(model, val_loader)  # Evaluate after each step\n",
    "        # print(f\"Validation at step [{batch_idx+1}/{len(train_loader)}] - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        run.log_metrics(\n",
    "            data = {\n",
    "                \"metrics/train/loss\": loss.item(),\n",
    "                \"metrics/train/accuracy\": batch_accuracy,\n",
    "                \"metrics/validation/loss\": val_loss,\n",
    "                \"metrics/validation/accuracy\": val_accuracy,\n",
    "                \"epoch_value\": epoch\n",
    "            },\n",
    "            step = step_counter\n",
    "        )\n",
    "    \n",
    "    # Print loss and accuracy for the entire training epoch\n",
    "    train_accuracy = correct_preds / total_preds\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Training complete. Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Track activations\n",
    "    for name, activation in model.get_activations().items():\n",
    "        activation_dict_mean[f\"layers/layer_{name}/activation_mean\"] = activation.mean().item()\n",
    "        activation_dict_std[f\"layers/layer_{name}/activation_std\"] = activation.std().item()\n",
    "\n",
    "    # Track gradients and norms per layer at each epoch\n",
    "    for name, param in model.named_parameters():\n",
    "        if param is not None:\n",
    "            params_dict_std[f\"layers/layer_{name}_std\"] = param.grad.std().item()\n",
    "            params_dict_mean[f\"layers/layer_{name}_mean\"] = param.grad.mean().item()\n",
    "            grad_norms[f\"grad_norm/{name}\"] = param.grad.norm(2).item() # L2 norm (Euclidean norm) of the gradients\n",
    "    \n",
    "    layers_dict = {**activation_dict_mean, \n",
    "                   **activation_dict_std,\n",
    "                   **params_dict_mean,\n",
    "                   **params_dict_std,\n",
    "                   **grad_norms\n",
    "                   }\n",
    "    print(layers_dict)\n",
    "\n",
    "    # data_to_log = {\n",
    "    #        \"metrics/test/loss_epoch\": epoch_loss / len(train_loader),\n",
    "     #       \"metrics/train/accuracy_epoch\": train_accuracy\n",
    "      #  }.update(activation_dict)\n",
    "    \n",
    "    run.log_metrics(\n",
    "    data = layers_dict,\n",
    "    step = epoch\n",
    "    )\n",
    "    \n",
    "# Final Testing Step with gradient tracking\n",
    "test_loss, test_accuracy = evaluate(model, test_loader, track_gradients=False)  # Track gradients during test\n",
    "print(f\"Testing complete. Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "run.log_configs(\n",
    "        {\n",
    "        \"metrics/test/loss\": test_loss,\n",
    "        \"metrics/test/accuracy\": test_accuracy\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neptune:INFO: Waiting for all operations to be processed\n",
      "neptune:WARNING: No timeout specified. Waiting indefinitely\n",
      "neptune:INFO: All operations were processed\n"
     ]
    }
   ],
   "source": [
    "run.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neptune_scale_py_312_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
