{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Neptune + PyTorch Lightning](https://neptune.ai/wp-content/uploads/2023/09/lightning.svg)\n",
    "\n",
    "# Neptune + PyTorch Lightning\n",
    "\n",
    "<!--<a target=\"_blank\" href=\"https://lightning.ai/neptuneai/studios/neptune-lightning\">\n",
    "  <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" height=\"20\" alt=\"Open In Studio\"/>\n",
    "</a>--> <a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/scale-examples/blob/lb/pytorch-lightning/integrations-and-supported-tools/pytorch-lightning/notebooks/Neptune_PyTorch_Lightning.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a><a target=\"_blank\" href=\"https://github.com/neptune-ai/scale-examples/blob/lb/pytorch-lightning/integrations-and-supported-tools/pytorch-lightning/notebooks/Neptune_PyTorch_Lightning.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a><a target=\"_blank\" href=\"https://scale.neptune.ai/o/examples/org/pytorch-lightning/runs/table?viewId=9ea6121c-42a7-4ece-83b2-c591044837e7&detailsTab=charts&dash=table&type=experiment\"> \n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a><!--<a target=\"_blank\" href=\"\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header",
     "comment"
    ]
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* Install the Neptune Scale-PyTorch Lightning integration\n",
    "* Create a `NeptuneScaleLogger()` instance\n",
    "* Use the logger to log metadata to Neptune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "  1. Create a Neptune Scale account. [Register &rarr;](https://neptune.ai/early-access)\n",
    "  2. Create a Neptune project that you will use for tracking metadata. For instructions, see [Projects](https://docs-beta.neptune.ai/projects/) in the Neptune Scale docs.\n",
    "  3. Install and configure Neptune Scale for logging metadata. For instructions, see [Get started](https://docs-beta.neptune.ai/setup) in the Neptune Scale docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Neptune and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q -U neptune-scale torchvision\n",
    "! pip install -q -U --user pydantic scikit-learn\n",
    "! pip install -q git+https://github.com/SiddhantSadangi/pytorch-lightning.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If running on Google Colab, restart the kernel and continue execution from the next cell to avoid a `ContextualVersionConflict` error.\n",
    "\n",
    "This error is caused by Colab coming with `future==0.16.0` preinstalled, while `torchvision` updates this to a newer version."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from lightning.pytorch.loggers.neptune import NeptuneScaleLogger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\": 64,\n",
    "    \"linear\": 32,\n",
    "    \"lr\": 0.001,\n",
    "    \"decay_factor\": 0.8,\n",
    "    \"max_epochs\": 3,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Define Lightning model\n",
    "\n",
    "To log metrics to Neptune, define a Lightning model with both inbuilt logging (`self.log()` or `self.log_dict()`) and custom logging (`neptune_logger.run`).\n",
    "\n",
    "`neptune_logger.run` is a reference to the Neptune run object created by the `NeptuneScaleLogger()` instance. You can use it to log outside the `prefix` passed to `NeptuneScaleLogger()`. It accepts Neptune's logging methods such as `log_configs()` and `log_metrics()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, linear, learning_rate, decay_factor):\n",
    "        super().__init__()\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.linear = linear\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_factor = decay_factor\n",
    "        self.train_img_max = 10\n",
    "        self.train_img = 0\n",
    "        self.layer_1 = torch.nn.Linear(28 * 28, linear)\n",
    "        self.layer_2 = torch.nn.Linear(linear, 20)\n",
    "        self.layer_3 = torch.nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layer_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = LambdaLR(optimizer, lambda epoch: self.decay_factor**epoch)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"train/batch/loss\", loss, prog_bar=False)\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = y_hat.argmax(axis=1).cpu().detach().numpy()\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        self.log(\"train/batch/acc\", acc)\n",
    "        self.training_step_outputs.append({\"loss\": loss, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        loss = np.array([])\n",
    "        y_true = np.array([])\n",
    "        y_pred = np.array([])\n",
    "        for results_dict in self.training_step_outputs:\n",
    "            loss = np.append(loss, results_dict[\"loss\"].cpu().detach().numpy())\n",
    "            y_true = np.append(y_true, results_dict[\"y_true\"])\n",
    "            y_pred = np.append(y_pred, results_dict[\"y_pred\"])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        self.logger.run.log_metrics(\n",
    "            data={\"train/epoch/loss\": loss.mean(), \"train/epoch/acc\": acc}, step=self.global_step\n",
    "        )\n",
    "\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = y_hat.argmax(axis=1).cpu().detach().numpy()\n",
    "\n",
    "        self.validation_step_outputs.append({\"loss\": loss, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = np.array([])\n",
    "        y_true = np.array([])\n",
    "        y_pred = np.array([])\n",
    "        for results_dict in self.validation_step_outputs:\n",
    "            loss = np.append(loss, results_dict[\"loss\"].cpu().detach().numpy())\n",
    "            y_true = np.append(y_true, results_dict[\"y_true\"])\n",
    "            y_pred = np.append(y_pred, results_dict[\"y_pred\"])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        # You can also use the log_dict() method from PTL\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"val/epoch/loss\": loss.mean(),\n",
    "                \"val/epoch/acc\": acc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = y_hat.argmax(axis=1).cpu().detach().numpy()\n",
    "\n",
    "        \"\"\"\n",
    "        # Log misclassified test images to Neptune\n",
    "        # Currently Neptune Scale does not support file uploads\n",
    "        # The example will be updated once file support is added\n",
    "        \"\"\"\n",
    "\n",
    "        self.test_step_outputs.append({\"loss\": loss, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        loss = np.array([])\n",
    "        y_true = np.array([])\n",
    "        y_pred = np.array([])\n",
    "        for results_dict in self.test_step_outputs:\n",
    "            loss = np.append(loss, results_dict[\"loss\"].cpu().detach().numpy())\n",
    "            y_true = np.append(y_true, results_dict[\"y_true\"])\n",
    "            y_pred = np.append(y_pred, results_dict[\"y_pred\"])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        self.log(\"test/loss\", loss.mean())\n",
    "        self.log(\"test/acc\", acc)\n",
    "        self.validation_step_outputs.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel(\n",
    "    linear=params[\"linear\"],\n",
    "    learning_rate=params[\"lr\"],\n",
    "    decay_factor=params[\"decay_factor\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, normalization_vector):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.normalization_vector = normalization_vector\n",
    "        self.mnist_train = None\n",
    "        self.mnist_val = None\n",
    "        self.mnist_test = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        MNIST(os.getcwd(), train=True, download=True)\n",
    "        MNIST(os.getcwd(), train=False, download=True)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.normalization_vector[0], self.normalization_vector[1]),\n",
    "            ]\n",
    "        )\n",
    "        if stage == \"fit\":\n",
    "            mnist_train = MNIST(os.getcwd(), train=True, transform=transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
    "        if stage == \"test\":\n",
    "            self.mnist_test = MNIST(os.getcwd(), train=False, transform=transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=0)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule(\n",
    "    normalization_vector=((0.1307,), (0.3081,)),\n",
    "    batch_size=params[\"batch_size\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Create a NeptuneScaleLogger() instance\n",
    "\n",
    "To create a new run for tracking the metadata, you tell Neptune who you are (`api_token`) and where to send the data (`project`).\n",
    "\n",
    "### Log to your own project instead\n",
    "\n",
    "Replace the code below with the following:\n",
    "\n",
    "```python\n",
    "from getpass import getpass\n",
    "\n",
    "neptune_logger = NeptuneScaleLogger(\n",
    "    project=\"workspace-name/project-name\",  # replace with your own (see instructions below)\n",
    "    api_token=getpass(\"Enter your Neptune API token: \"),\n",
    "    experiment_name=\"lightning-experiment\"  # Optional experiment name\n",
    ")\n",
    "```\n",
    "\n",
    "To find your API token and full project name:\n",
    "\n",
    "1. [Log in to Neptune](https://scale.neptune.ai/).\n",
    "1. In the bottom-left corner, expand your user menu and select **Get your API token**.\n",
    "1. You can copy the project path from the project.\n",
    "\n",
    "For more help, see [Get your API token](https://docs-beta.neptune.ai/setup#3-get-your-api-token) in the Neptune docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneScaleLogger(\n",
    "    # api_key = \"YOUR_API_KEY\",\n",
    "    # project = \"YOUR_WORKSPACE_NAME/YOUR_PROJECT_NAME\"\n",
    "    experiment_name=\"lightning-experiment\",\n",
    ")\n",
    "\n",
    "# Print run URL\n",
    "print(f\"Neptune run URL: {neptune_logger.run.get_run_url()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tags using the Neptune methods\n",
    "neptune_logger.run.add_tags([\"notebook\", \"lightning\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Initialize a trainer and pass neptune_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=neptune_logger,\n",
    "    max_epochs=params[\"max_epochs\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Log hyperparameters to the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neptune_logger.log_hyperparams(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log model summary to the run\n",
    "\n",
    "_Currently not supported._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune_logger.log_model_summary(model=model, max_depth=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Train and test the model and log metadata to the run live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=dm)\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the metadata being logged live, open the run in the Neptune app.\n",
    "\n",
    "You can ignore any \"X-coordinates (step) must be strictly increasing\" errors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging\n",
    "\n",
    "Once you are done logging, you should stop the run using the `close()` method, which is a method of the run object. The run object itself is part of the `neptune_logger`.\n",
    "This is needed only while logging from a notebook environment. While logging through a script, Neptune automatically stops tracking once the script has completed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "neptune_logger.run.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "## Analyze logged metadata in the Neptune app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "comment"
    ]
   },
   "source": [
    "To explore the metadata in Neptune, follow the link in the console output.\n",
    "\n",
    "It looks something like [this](https://scale.neptune.ai/o/examples/org/pytorch-lightning/runs/details?viewId=standard-view&detailsTab=charts&runIdentificationKey=lightning-experiment&type=experiment)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neptune_PyTorch_Lightning.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
