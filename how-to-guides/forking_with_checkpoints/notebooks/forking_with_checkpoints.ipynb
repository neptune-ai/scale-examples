{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we show how you can use Neptune to create forks from previous runs when/if;\n",
    "1. Create a new run (fork) from any previously saved checkpoint with a different set of hyperparameters\n",
    "2. Your training run experiences training instability and you'd like to restart a new run from a previous checkpoint\n",
    "3. A drop in hardware causes training problems and you need to restart the training run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune_scale import Run\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": (1, 28, 28),\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 3,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "input_size = math.prod(parameters[\"input_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_parameters = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)  # Flatten 28*28 pixels to 128 neurons\n",
    "        self.fc2 = nn.Linear(128, 10)     # 10 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the image (batch_size, 28, 28) -> (batch_size, 28*28)\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU after the first linear layer\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "trainset = datasets.MNIST(\n",
    "    root=\"mnist\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=data_tfms[\"train\"],\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=parameters[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(\n",
    "    input_size,\n",
    ").to(parameters[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint file\n",
    "# Function to save the checkpoint\n",
    "import os\n",
    "def save_checkpoint(epoch, step, model, optimizer, loss):\n",
    "    # Function saves the checkpoint locally\n",
    "    checkpoint_dir = './checkpoints'\n",
    "\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "# Function to load the checkpoint\n",
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    step = checkpoint['step']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from step {step}, epoch {epoch}, loss: {loss:.4f}\")\n",
    "    return epoch, step, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generic training loop with Neptue logging\n",
    "def train(model: nn.Module, updating_parameters, trainloader, run: Run = None, step = 0):\n",
    "    # Training loop\n",
    "    step_counter = step\n",
    "    optimizer = optim.Adam(model.parameters(), lr=updating_parameters[\"learning_rate\"])\n",
    "    for epoch in range(1, updating_parameters[\"epochs\"] + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(trainloader, start=step+1):\n",
    "            step_counter += 1\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Log loss to Neptune\n",
    "            if run is not None:\n",
    "                run.log_metrics(\n",
    "                    data={\n",
    "                        \"train/loss\": loss.item(),\n",
    "                        \"train/epoch\": epoch\n",
    "                    },\n",
    "                    step=step_counter\n",
    "                )\n",
    "\n",
    "        # Print average loss for the epoch\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        print(f\"Epoch {epoch} average loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoint after each epoch\n",
    "        save_checkpoint(epoch, step_counter, model, optimizer, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scale.neptune.ai/leo/pytorch-tutorial/runs/details?runIdentificationKey=head_of_forking&type=experiment\n"
     ]
    }
   ],
   "source": [
    "# Create initial experiment (fancy run)\n",
    "\n",
    "run = Run(experiment_name=\"head_of_forking\")\n",
    "\n",
    "run.log_configs({\n",
    "    \"paramters/intial/config/n_classes\": parameters[\"n_classes\"],\n",
    "    \"paramters/changing/config/epochs\": updating_parameters[\"epochs\"],\n",
    "    \"paramters/changing/config/lr\": updating_parameters[\"learning_rate\"],\n",
    "    \"paramters/changing/config/batch_size\": updating_parameters[\"batch_size\"],\n",
    "})\n",
    "\n",
    "run.add_tags([\"forks\", \"notebook\"])\n",
    "\n",
    "print(run.get_experiment_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 0.4472\n",
      "Checkpoint saved at epoch 1\n",
      "Epoch 2 average loss: 0.4196\n",
      "Checkpoint saved at epoch 2\n",
      "Epoch 3 average loss: 0.4100\n",
      "Checkpoint saved at epoch 3\n",
      "Epoch 4 average loss: 0.4055\n",
      "Checkpoint saved at epoch 4\n",
      "Epoch 5 average loss: 0.4272\n",
      "Checkpoint saved at epoch 5\n",
      "Epoch 6 average loss: 0.3910\n",
      "Checkpoint saved at epoch 6\n",
      "Epoch 7 average loss: 0.4181\n",
      "Checkpoint saved at epoch 7\n",
      "Epoch 8 average loss: 0.4615\n",
      "Checkpoint saved at epoch 8\n",
      "Epoch 9 average loss: 0.4319\n",
      "Checkpoint saved at epoch 9\n",
      "Epoch 10 average loss: 0.4553\n",
      "Checkpoint saved at epoch 10\n"
     ]
    }
   ],
   "source": [
    "# Execute training loop for initial experiment\n",
    "train(model, updating_parameters, trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 16:53:32,430 neptune:INFO: Waiting for all operations to be processed\n",
      "2025-03-28 16:53:32,430 neptune:WARNING: No timeout specified. Waiting indefinitely\n",
      "2025-03-28 16:53:32,431 neptune:INFO: All operations were processed\n"
     ]
    }
   ],
   "source": [
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from step 8442, epoch 9, loss: 0.4319\n"
     ]
    }
   ],
   "source": [
    "# Start a fork from each checkpoint\n",
    "\n",
    "checkpoint_path = os.path.join('./checkpoints', 'checkpoint_epoch_9.pth')\n",
    "optimizer = optim.Adam(model.parameters(), lr=updating_parameters[\"learning_rate\"])\n",
    "\n",
    "epoch, step, loss = load_checkpoint(model, optimizer, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a forked run\n",
    "run = Run(\n",
    "    experiment_name=\"forked_experiment\",\n",
    "    fork_run_id=\"\",\n",
    "    fork_step=step\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neptune_scale_py_312_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
