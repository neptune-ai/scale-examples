{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fork Training Runs with Neptune\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neptune-ai/scale-examples/blob/lb/forking-long-runs/how-to-guides/forking-long-runs/fork_long_training_runs.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/> \n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/neptune-ai/scale-examples/blob/lb/forking-long-runs/how-to-guides/debug-model-training-runs/debug_training_runs.ipynb\">\n",
    "  <img alt=\"Open in GitHub\" src=\"https://img.shields.io/badge/Open_in_GitHub-blue?logo=github&labelColor=black\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://docs-beta.neptune.ai/tutorials/\">\n",
    "  <img alt=\"View tutorial in docs\" src=\"https://neptune.ai/wp-content/uploads/2024/01/docs-badge-2.svg\">\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://scale.neptune.ai/leo/pytorch-tutorial/reports/9ec24024-08dd-45c4-8d82-51b916054fb6\">\n",
    "  <img alt=\"Explore in Neptune\" src=\"https://neptune.ai/wp-content/uploads/2024/01/neptune-badge.svg\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Training large models can take weeks or months. During these long runs, you may need to:\n",
    "- Resume from checkpoints after training instabilities\n",
    "- Fork runs to try different hyperparameters\n",
    "- Monitor total training progress and lineage\n",
    "\n",
    "This tutorial shows you how to:\n",
    "1. **Initialize Neptune** for long runs\n",
    "2. Create a **forked training run** when needed\n",
    "3. **Restart training** from checkpoints\n",
    "\n",
    "_Note: This is a code recipe that you can adapt for your own model training needs._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "  1. Create a Neptune Scale account. [Register &rarr;](https://neptune.ai/early-access)\n",
    "  2. Create a Neptune project for tracking metadata. For instructions, see [Projects](https://docs-beta.neptune.ai/projects/) in the Neptune Scale docs.\n",
    "  3. Install and configure Neptune Scale for logging metadata. For instructions, see [Get started](https://docs-beta.neptune.ai/setup) in the Neptune Scale docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment variables\n",
    "Set your project name and API token as environment variables to log to your Neptune Scale project.\n",
    "\n",
    "Uncomment the code block below and replace placeholder values with your own credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Neptune credentials as environment variables\n",
    "# %env NEPTUNE_API_TOKEN = YOUR_API_TOKEN\n",
    "# %env NEPTUNE_PROJECT = WORKSPACE_NAME/PROJECT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "! pip install -qU neptune-scale torch torchvision \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training code\n",
    "\n",
    "This tutorial demonstrates Neptune's forking capabilities using a simple MNIST neural network. The code includes:\n",
    "- A configurable multi-layer model (`SimpleModel`)\n",
    "- Training loop with metrics\n",
    "- Checkpoint management (saving and loading methods)\n",
    "\n",
    "The next cell sets up the model architecture, checkpoint utilities, and training components.\n",
    "\n",
    "_You can replace this simulation with your actual model training code._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 784,\n",
    "        hidden_size: int = 128,\n",
    "        output_size: int = 10,\n",
    "        num_layers: int = 10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        # Combine all layers into a sequential model\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Function to save the checkpoint\n",
    "import os\n",
    "\n",
    "\n",
    "def save_checkpoint(epoch, global_step, model, optimizer, run):\n",
    "    # Function saves the checkpoint locally\n",
    "    checkpoint_dir = \"./checkpoints\"\n",
    "\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"run_id\": run._run_id,\n",
    "            \"epoch\": epoch,\n",
    "            \"global_step\": global_step,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "        checkpoint_path,\n",
    "    )\n",
    "    print(f\"Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "\n",
    "# Function to load the checkpoint\n",
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    global_step = checkpoint[\"global_step\"]\n",
    "    print(\n",
    "        f\"Checkpoint created by experiment ID {checkpoint['run_id']}, loaded from step {global_step}, epoch {epoch}\"\n",
    "    )\n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "# Define a generic training loop with Neptue logging\n",
    "from neptune_scale import Run\n",
    "\n",
    "\n",
    "def train(\n",
    "    run: Run,\n",
    "    model: nn.Module,\n",
    "    params,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    epoch_start=0,\n",
    "    step_start=0,\n",
    "    forked=False,\n",
    "):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    step_counter = step_start\n",
    "    for epoch in range(epoch_start, epoch_start + params[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Move data to device\n",
    "            data, target = data.to(params[\"device\"]), target.to(params[\"device\"])\n",
    "            data = data.view(data.size(0), -1)  # Flatten the images\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "\n",
    "            running_loss += batch_loss\n",
    "\n",
    "            run.log_metrics(\n",
    "                data={\n",
    "                    \"metrics/train/loss\": batch_loss,\n",
    "                    \"epoch\": epoch,\n",
    "                },\n",
    "                step=step_counter,\n",
    "            )\n",
    "            step_counter += 1\n",
    "\n",
    "        # Save checkpoint after each epoch\n",
    "        if not forked:\n",
    "            save_checkpoint(epoch, step_counter, model, optimizer, run)\n",
    "\n",
    "    run.close()\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "params = {\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 15,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_layers\": 20,  # Configurable number of layers\n",
    "    \"seed\": 42,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "# Make experiments reproducible\n",
    "torch.manual_seed(params[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create forked runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: _Create initial base experiment_\n",
    "\n",
    "Create a base experiment that represents a long training process. This could be your best performing model from hyperparameter optimization that you want to train further.\n",
    "\n",
    "The training loop will:\n",
    "1. Log training metrics (`loss`) at each step\n",
    "2. Save model state (checkpoint) every epoch\n",
    "\n",
    "By saving checkpoints (or model state) periodically, we can restart training from any saved state. Neptune's forking capability allows us to create new runs that inherit the training history, making it easy to visualize the complete training progression across multiple runs.\n",
    "\n",
    "See our [Quickstart](https://docs.neptune.ai/quickstart) if you have not created a Neptune run before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune_scale import Run\n",
    "\n",
    "run = Run(\n",
    "    experiment_name=\"forking-example-initial\",  # Create a run that is the head of an experiment\n",
    ")\n",
    "\n",
    "run.log_configs(\n",
    "    {\n",
    "        \"config/batch_size\": params[\"batch_size\"],\n",
    "        \"config/epochs\": params[\"epochs\"],\n",
    "        \"config/lr\": params[\"lr\"],\n",
    "        \"config/num_layers\": params[\"num_layers\"],\n",
    "        \"config/seed\": params[\"seed\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "run.add_tags(tags=[\"forking\"])\n",
    "\n",
    "# Initialize model andoptimizer\n",
    "model = SimpleModel(num_layers=params[\"num_layers\"]).to(params[\"device\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "# Execute training loop for initial experiment\n",
    "train(run, model, params, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load model state and create forked run\n",
    "\n",
    "As training instabilities start occuring, we may decide to restart our training from one of our saved model states. We can then pick a model state to restart training from and tell Neptune to inherit our training history from the previous experiment. \n",
    "\n",
    "To create a forked run, we need to do the following;\n",
    "1. Load our saved model state\n",
    "2. Create a forked run using the Neptune `Run` object\n",
    "3. Log metrics to the forked run\n",
    "\n",
    "#### _Step 2.1: Load model state (checkpoint)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint that you want to fork from\n",
    "checkpoint = load_checkpoint(model, optimizer, f\"./checkpoints/checkpoint_epoch_{3}.pth\")\n",
    "\n",
    "params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 0.0001,\n",
    "    \"num_layers\": 20,  # Configurable number of layers\n",
    "    \"seed\": 42,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=params[\"batch_size\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Step 2.2: Create a forked run_\n",
    "\n",
    "To create a forked run, you need:\n",
    "- The **run ID** of the original run to fork from cab be:\n",
    "  - Accessed via `run._run_id` property (saved to the checkpoint file)\n",
    "  - Found in Neptune web app\n",
    "  - Fetched programmatically using `neptune-fetcher` package\n",
    "- The **step** number to fork from\n",
    "\n",
    "Here's an example of how to create a forked run:\n",
    "```python\n",
    "forked_run = Run(\n",
    "    ...\n",
    "    fork_run_id=\"ID_OF_RUN_TO_FORK\", # ID of the run to fork from\n",
    "    fork_step=1234                   # Step at which to fork the run\n",
    ")\n",
    "```\n",
    "\n",
    "See [fork an experiment](https://docs.neptune.ai/fork_experiment) for more details of forking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a forked run\n",
    "print(f\"Forking run with ID: {checkpoint['run_id']}\")\n",
    "\n",
    "forked_run = Run(\n",
    "    experiment_name=\"forking-single\",  # Becomes new head of the experiment\n",
    "    fork_run_id=checkpoint[\"run_id\"],\n",
    "    fork_step=checkpoint[\"global_step\"],  # Fork from the step where the checkpoint was saved\n",
    ")\n",
    "\n",
    "# Log the forked configuration\n",
    "forked_run.log_configs(\n",
    "    {\n",
    "        \"config/batch_size\": params[\"batch_size\"],\n",
    "        \"config/epochs\": params[\"epochs\"],\n",
    "        \"config/lr\": params[\"lr\"],\n",
    "        \"config/num_layers\": params[\"num_layers\"],\n",
    "        \"config/seed\": params[\"seed\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "forked_run.add_tags(tags=[\"fork\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Step 2.3: Log forked run metrics_\n",
    "\n",
    "Log metrics as normal using the `log_metrics()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(f\"Forking from epoch - {checkpoint['epoch']} and, step - {checkpoint['global_step']}\")\n",
    "\n",
    "train(\n",
    "    forked_run,\n",
    "    model,\n",
    "    params,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    step_start=checkpoint[\"global_step\"] + 1,\n",
    "    epoch_start=checkpoint[\"epoch\"],\n",
    "    forked=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced: Launch multiple forks from a single parent\n",
    "\n",
    "In this section, we demonstrate how multiple forks can be created from a single parent to test various parameters to analyse convergence. We can easily setup a parallel execution of experiments using the code we have setup previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from neptune_scale import Run\n",
    "\n",
    "\n",
    "def run_single_experiment(params, train_loader):\n",
    "    \"\"\"Function to run a single experiment\"\"\"\n",
    "\n",
    "    # Create a fresh model instance for this experiment\n",
    "    model = SimpleModel(num_layers=20).to(params[\"device\"])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "    # Load the checkpoint into this fresh model\n",
    "    checkpoint_data = torch.load(f\"./checkpoints/checkpoint_epoch_{3}.pth\")\n",
    "    model.load_state_dict(checkpoint_data[\"model_state_dict\"])\n",
    "    # optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])\n",
    "\n",
    "    with Run(\n",
    "        experiment_name=f\"forking-parallel-lr={params['lr']}-bs={params['batch_size']}\",\n",
    "        fork_run_id=checkpoint_data[\"run_id\"],\n",
    "        fork_step=checkpoint_data[\"global_step\"],\n",
    "    ) as run:\n",
    "\n",
    "        run.add_tags([\"parallel\", \"forked\"])\n",
    "        run.log_configs(\n",
    "            {\n",
    "                \"config/batch_size\": params[\"batch_size\"],\n",
    "                \"config/epochs\": params[\"epochs\"],\n",
    "                \"config/lr\": params[\"lr\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\"Training forked run\")\n",
    "        # Your training code here\n",
    "        train(\n",
    "            run,\n",
    "            model,\n",
    "            params,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            step_start=checkpoint_data[\"global_step\"] + 1,\n",
    "            epoch_start=checkpoint_data[\"epoch\"],\n",
    "            forked=True,\n",
    "        )\n",
    "\n",
    "        return run.get_run_url()\n",
    "\n",
    "\n",
    "# Launch multiple runs in parallel\n",
    "trial_configs = [\n",
    "    {\"lr\": 0.001, \"batch_size\": 256, \"epochs\": 10, \"device\": \"cpu\"},\n",
    "    {\"lr\": 0.0001, \"batch_size\": 256, \"epochs\": 10, \"device\": \"cpu\"},\n",
    "    {\"lr\": 0.00001, \"batch_size\": 256, \"epochs\": 10, \"device\": \"cpu\"},\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    # Submit all experiments\n",
    "    futures = [\n",
    "        executor.submit(run_single_experiment, config, train_loader) for config in trial_configs\n",
    "    ]\n",
    "\n",
    "    # Wait for all to complete\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            future.result()  # This will raise any exceptions\n",
    "        except Exception as e:\n",
    "            print(f\"Experiment failed: {e}\")\n",
    "\n",
    "print(\"All experiments completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: _Analyzing forked experiments_\n",
    "\n",
    "When you fork a run in Neptune, the system automatically tracks key relationships in the `sys/forking` namespace:\n",
    "\n",
    "| Property | Description | Example |\n",
    "|----------|-------------|---------|\n",
    "| `depth` | Number of forks from original run | 1 |\n",
    "| `parent` | ID of immediate parent run | expansive-strategy-20250428124036156-fzp9y |\n",
    "| `step` | Training step where fork occurred | 9704 |\n",
    "\n",
    "#### Key Analysis Capabilities\n",
    "1. **Compare Runs**: Use Neptune's comparison mode to analyze base and forked runs side-by-side\n",
    "2. **Visualize Lineage**: Track relationships and evolution between forked runs\n",
    "3. **Iterate & Improve**: Create additional forks to explore different approaches\n",
    "\n",
    "For a practical example, check out this [training report](https://scale.neptune.ai/leo/pytorch-tutorial/reports/9ec24024-08dd-45c4-8d82-51b916054fb6) showcasing forking in action.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neptune_scale_py_312_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
